{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab7bd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "from opensearchpy import OpenSearch, helpers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "INDEX_NAME = \"enron-semantic-2\"\n",
    "DIMENSION = 384  # For 'all-MiniLM-L6-v2'\n",
    "EMBEDDING_MODEL = 'all-MiniLM-L6-v2'\n",
    "\n",
    "# Connect to OpenSearch\n",
    "client = OpenSearch(\n",
    "    hosts=[{'host': 'localhost', 'port': 9200}],\n",
    "    #http_auth=('admin', 'admin'),  # adjust if needed\n",
    "    use_ssl=False\n",
    ")\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(EMBEDDING_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3d03032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top matches for: \"Whatâ€™s our plan for the next quarter?\"\n",
      "\n",
      "- {'file': 'bass-e/inbox/55.', 'message-id': '<14068132.1075840320520.JavaMail.evans@thyme>', 'from': 'timothy.blanchard@enron.com', 'to': 'eric.bass@enron.com', 'x-to': 'Bass, Eric </O=ENRON/OU=NA/CN=RECIPIENTS/CN=Ebass>', 'x-cc': '', 'x-bcc': '', 'subject': 'Super Bowl', 'date': 'Wed, 30 Jan 2002 08:53:42 -0800', 'body': \"What's the plan?\"} (score: 0.5916)\n",
      "- {'file': 'hayslett-r/projects/portland_general/35.', 'message-id': '<13358943.1075862295606.JavaMail.evans@thyme>', 'from': 'kirk.stevens@enron.com', 'to': 'rod.hayslett@enron.com, geaccone.enron.ene.tracy@enron.com', 'x-to': 'Hayslett, Rod </O=ENRON/OU=NA/CN=RECIPIENTS/CN=RHAYSLE>, Enron.ENE.Tracy Geaccone <??EEnron.ENE.Tracy Geaccone>', 'x-cc': 'Piro, Jim </O=ENRON/OU=NA/CN=RECIPIENTS/CN=GWADDR/CN=HQ3.EM5.JIM PIRO>, FOWLER, PEGGY </O=ENRON/OU=NA/CN=RECIPIENTS/CN=GWADDR/CN=HQ3.EM5.PEGGY FOWLER>', 'x-bcc': '', 'subject': 'Q3 Earnings - PGG', 'date': 'Tue, 21 Aug 2001 12:58:00 -0700', 'body': 'Rod, per your request, attached is an analysis to use in your discussion\\ntomorrow with Stan Horton regarding PGG\\'s expected financial results for Q3. \\nMore specifically, I laid out a plan as to how we might cover our current\\noverview gap of $19.5m (IBIT) from where our latest forecast came out.  As you\\nwill see, several of these items will need to get AA&Co buy-in (items noted as\\neither Accouting Changes or Changes in Management Position).  I think we have\\na good case for all of these, but we still need to go through the process with\\nthem at the appropriate time.\\n\\nIn addition, I\\'ve note \"Other Risks/Opportunities\" for the quarter that could\\nhave significant impacts on our ultimate results.  We will keep an eye on\\nthese and manage them as appropriate.  We\\'ll also try to keep you updated on\\nthese as we progress through the Qtr.\\n\\nLet me know if you have any questions.'} (score: 0.5466)\n",
      "- {'file': 'lucci-p/sent_items/235.', 'message-id': '<20995838.1075862127043.JavaMail.evans@thyme>', 'from': 't..lucci@enron.com', 'to': 'christina_122367@hotmail.com', 'x-to': 'Christina Rawlings-Curtis (E-mail) <christina_122367@hotmail.com>', 'x-cc': '', 'x-bcc': '', 'subject': '', 'date': 'Tue, 06 Nov 2001 08:18:10 -0800', 'body': \"What's Up?!  What's OUR plan later this week?  What day/time/where?\"} (score: 0.5267)\n"
     ]
    }
   ],
   "source": [
    "# Semantic Search\n",
    "query_text = \"Whatâ€™s our plan for the next quarter?\"\n",
    "query_vector = model.encode(query_text).tolist()\n",
    "\n",
    "search_body = {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"knn\": {\n",
    "            \"body_vector\": {\n",
    "                \"vector\": query_vector,\n",
    "                \"k\": 3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = client.search(index=INDEX_NAME, body=search_body)\n",
    "\n",
    "print(f\"\\nTop matches for: \\\"{query_text}\\\"\\n\")\n",
    "for hit in results[\"hits\"][\"hits\"]:\n",
    "    print(f\"- {hit['_source']['message']} (score: {hit['_score']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad493b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§  Gemini Summary:\n",
      "The emails cover two main topics:\n",
      "\n",
      "*   Two emails are simple inquiries about plans: one asks about \"Super Bowl\" plans, and another asks for details (day, time, where) for \"our plan later this week.\"\n",
      "*   The third email provides a financial analysis and a plan to cover a $19.5 million gap in PGG's expected Q3 financial results, noting that some items require auditor approval and mentioning other risks/opportunities.\n"
     ]
    }
   ],
   "source": [
    "# ----------- Summarize with Gemini ----------- #\n",
    "import google.generativeai as genai\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "messages = [hit[\"_source\"][\"message\"] for hit in results[\"hits\"][\"hits\"]]\n",
    "\n",
    "prompt = \"Summarize the following email messages:\\n\\n\"\n",
    "for i, msg in enumerate(messages, 1):\n",
    "    prompt += f\"{i}. {msg}\\n\"\n",
    "prompt += \"\\nSummary:\"\n",
    "\n",
    "GEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "gemini_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "\n",
    "response = gemini_model.generate_content({\n",
    "    \"text\": prompt\n",
    "})\n",
    "\n",
    "print(\"\\nðŸ§  Gemini Summary:\")\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
